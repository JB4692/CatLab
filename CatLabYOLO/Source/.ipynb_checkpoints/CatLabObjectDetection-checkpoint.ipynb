{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2639f-d9f2-45ce-a90e-48a32b0a95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!which python for linux and mac\n",
    "!where python   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b64781e-5f97-4b93-ab6a-35f4bfe416a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def check_opencv():\n",
    "    print(f\"✅ OpenCV Version: {cv2.__version__}\")\n",
    "\n",
    "    try:\n",
    "        dnn_info = cv2.getBuildInformation()\n",
    "        if \"CUDA\" in dnn_info:\n",
    "            print(\"🔍 Checking OpenCV DNN build...\")\n",
    "            print(dnn_info.split(\"CUDA\")[1].split(\"\\n\")[0].strip())  # Show CUDA status\n",
    "        else:\n",
    "            print(\"⚠️ CUDA information not found in OpenCV build.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error checking OpenCV build: {e}\")\n",
    "\n",
    "def check_cuda():\n",
    "    try:\n",
    "        net = cv2.dnn.readNet(\"yolov4.weights\", \"yolov4.cfg\")\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "        print(\"✅ CUDA is available for OpenCV DNN!\")\n",
    "    except cv2.error as e:\n",
    "        print(\"❌ CUDA is NOT available for OpenCV DNN.\")\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def check_files():\n",
    "    files = [\"yolov4.cfg\", \"yolov4.weights\", \"coco.names\"]\n",
    "    missing = [f for f in files if not os.path.exists(f)]\n",
    "    if missing:\n",
    "        print(f\"❌ Missing files: {', '.join(missing)}\")\n",
    "    else:\n",
    "        print(\"✅ All YOLO files are present!\")\n",
    "\n",
    "def check_dependencies():\n",
    "    print(\"🔍 Checking dependencies...\\n\")\n",
    "    \n",
    "    # Check OpenCV and CUDA\n",
    "    check_opencv()\n",
    "    check_cuda()\n",
    "    \n",
    "    # Check if YOLO files exist\n",
    "    check_files()\n",
    "    \n",
    "    print(\"\\n🔍 Dependency check complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa10c833-e656-4eb0-a975-20b6db942ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking dependencies...\n",
      "\n",
      "✅ OpenCV Version: 4.11.0\n",
      "⚠️ CUDA information not found in OpenCV build.\n",
      "✅ CUDA is available for OpenCV DNN!\n",
      "✅ All YOLO files are present!\n",
      "\n",
      "🔍 Dependency check complete!\n"
     ]
    }
   ],
   "source": [
    "# Check for dependencies\n",
    "check_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb016077-6735-4442-aa44-0ae971a85642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO model...\n",
      "YOLO model loaded successfully!\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\net_impl.cpp:120: error: (-215:Assertion failed) preferableBackend != DNN_BACKEND_CUDA || IS_DNN_CUDA_TARGET(preferableTarget) in function 'cv::dnn::dnn4_v20241223::Net::Impl::validateBackendAndTarget'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(frame, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m, (\u001b[38;5;241m416\u001b[39m, \u001b[38;5;241m416\u001b[39m), swapRB\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m net\u001b[38;5;241m.\u001b[39msetInput(blob)\n\u001b[1;32m---> 53\u001b[0m detections \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mforward(output_layers)\n\u001b[0;32m     55\u001b[0m results \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Store object data\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m detections:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\net_impl.cpp:120: error: (-215:Assertion failed) preferableBackend != DNN_BACKEND_CUDA || IS_DNN_CUDA_TARGET(preferableTarget) in function 'cv::dnn::dnn4_v20241223::Net::Impl::validateBackendAndTarget'\n"
     ]
    }
   ],
   "source": [
    "# !! READ ME !!\n",
    "# If you run this program it turns on your webcam\n",
    "\n",
    "# NOTES\n",
    "# TODO: Data Augmentation to create a very large dataset\n",
    "# Use https://www.makesense.ai/ to annotate our images once we have them\n",
    "# We will annotate 3 images per card, each with slightly different rotations\n",
    "# Focus on realistic variations based  on our set up\n",
    "# We only need to label a few key images (the cards on the setup), then use those labeled images to generate others with data augmentation\n",
    "# Since the environment is controlled, we don’t need to label every single variatio. Just the original images and a maybe few augmentations\n",
    "\n",
    "# LATER\n",
    "# When or if we switch to using sockets for reading in real time, write to a json and read in Godot via UDP\n",
    "\n",
    "# Paths for easy access\n",
    "cfg_path = \"yolov4.cfg\"\n",
    "weights_path = \"yolov4.weights\"\n",
    "names_path = \"coco.names\"\n",
    "\n",
    "# Load YOLO Model\n",
    "net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()] # Returns a tuple\n",
    "\n",
    "# Load class labels\n",
    "with open(names_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# IMPORTANT: Update classes and filters in the config file (TODO)\n",
    "\n",
    "print(\"Loading YOLO model...\")\n",
    "try:\n",
    "    net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)  # Use GPU if available\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "    print(\"YOLO model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading YOLO:\", e)\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)  # Use 0 for webcam but we can also use a video path, 1 for camera\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Prepare input image for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward(output_layers)\n",
    "\n",
    "    results = []  # Store object data\n",
    "\n",
    "    for output in detections:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                results.append({\n",
    "                    \"id\": class_id,  # Object class ID\n",
    "                    \"label\": classes[class_id],  # Class name\n",
    "                    \"x\": center_x,\n",
    "                    \"y\": center_y,\n",
    "                    \"confidence\": float(confidence)\n",
    "                })\n",
    "\n",
    "                # Draw detection\n",
    "                cv2.circle(frame, (center_x, center_y), 5, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, f\"{classes[class_id]} ({center_x}, {center_y})\",\n",
    "                            (center_x - 10, center_y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5, (255, 0, 0), 2)\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow(\"YOLO Object Detection\", frame)\n",
    "\n",
    "    # TODO: Send data to Godot (could use networking with sockets or file writing based solution)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # q to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f232dc1-485f-4b04-8f0f-14d3f28f7c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
